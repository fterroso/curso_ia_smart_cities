{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlMnduqUMYo4"
      },
      "source": [
        "# Deep Learning con Python\n",
        "\n",
        "## Redes Neuronales Recurrentes (RNN)\n",
        "\n",
        "En esta parte del taller vamos a estudiar las **redes recurrentes** aplicadas a la predicción horario de temperatura. Se implementan y comparan tres arquitecturas:\n",
        "\n",
        "- RNN simple (`SimpleRNN`)\n",
        "- LSTM (`LSTM`)\n",
        "- GRU (`GRU`)\n",
        "\n",
        "Este notebook  incluye:\n",
        "- Obtención de datos horarios desde la API pública de Open-Meteo (función proporcionada por el enunciado adaptada a una clase `TemperatureFetcher`).\n",
        "- Preprocesado (resampling, escalado, creación de secuencias).\n",
        "- Implementación de modelos Keras para predicción 1-step y forecasting multi-step (modo autoregresivo vs usar los datos reales como entradas).\n",
        "- Experimentos con diferentes horizontes de predicción y métricas de evaluación.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "id": "qlMnduqUMYo4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Predicción de series temporales ¿Qué es eso?"
      ],
      "metadata": {
        "id": "cK1bclFKN7Dc"
      },
      "id": "cK1bclFKN7Dc"
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(url=\"https://raw.githubusercontent.com/fterroso/curso_ia_smart_cities/main/img/ml_forecasting_multi-step.gif\",width=900, height=300))"
      ],
      "metadata": {
        "id": "BtF5LsblOXOr"
      },
      "id": "BtF5LsblOXOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ello vamos a seguir el mismo flujo de trabajo que ya usamos a la hora de desarrollar nuestro MLP"
      ],
      "metadata": {
        "id": "xcIwBvbSRkuB"
      },
      "id": "xcIwBvbSRkuB"
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(url=\"https://raw.githubusercontent.com/fterroso/curso_ia_smart_cities/main/img/ml_pipeline.jpg\",width=800, height=300))"
      ],
      "metadata": {
        "id": "fg4Q_0bTRqjQ"
      },
      "id": "fg4Q_0bTRqjQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CwUquPzWKIGc"
      },
      "id": "CwUquPzWKIGc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Librerías principales"
      ],
      "metadata": {
        "id": "BMwpBs8XTyBL"
      },
      "id": "BMwpBs8XTyBL"
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "EzY2yVqrTxMT"
      },
      "id": "EzY2yVqrTxMT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "R7mdBrokJseS"
      },
      "id": "R7mdBrokJseS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZBjGpXVMYpC"
      },
      "source": [
        "## 2) Obtener la serie temporal sobre la que vamos a trabajar\n",
        "\n",
        "En esta sección definimos una pequeña clase  `TemperatureFetcher` cuya responsabilidad es encapsular la descarga de un histórico de datos de temperatura horaria desde la API pública de `Open‑Meteo`.\n",
        "\n",
        "\n",
        "#### Qué hace exactamente esta clase\n",
        "\n",
        "\n",
        "- *Constructor (`__init__`)*: guarda las coordenadas (`latitude`, `longitude`) del lugar para el que queremos descargar datos.\n",
        "- Método `_fetch_historical_temperature(start_date, end_date)`:\n",
        "- Construye la petición HTTP al endpoint de archivo (`archive-api.open-meteo.com/v1/archive`) indicando latitud, longitud, rango de fechas y que queremos la variable `temperature_2m` con resolución horaria.\n",
        "- Llama a la API con `requests.get(...)` y comprueba el código HTTP de respuesta. Si la respuesta es correcta, convierte la parte `hourly` del JSON en un `pandas.DataFrame` y convierte la columna `time` a `datetime` y la coloca como índice.\n",
        "- Maneja errores básicos imprimiendo un mensaje si la respuesta no es 200 o si la respuesta no contiene la clave esperada.\n",
        "\n",
        "\n",
        "#### Formato de salida\n",
        "\n",
        "Devuelve un `pd.DataFrame` con al menos dos columnas: `time` (convertida y usada como índice) y `temperature_2m`. En el notebook renombramos `temperature_2m` a `temp` y construimos a partir de ahí la serie horaria que usaremos para el resto del pipeline."
      ],
      "id": "YZBjGpXVMYpC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1A_WnGZMYpE"
      },
      "outputs": [],
      "source": [
        "class TemperatureFetcher:\n",
        "    def __init__(self, latitude: float, longitude: float):\n",
        "        self.lat = latitude\n",
        "        self.lon = longitude\n",
        "\n",
        "    def _fetch_historical_temperature(self, start_date: datetime.date, end_date: datetime.date) -> pd.DataFrame:\n",
        "        base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "        print(f\"\\n\\tFetching weather data from Open-Meteo...\", end=\"\")\n",
        "        payload = {\n",
        "            \"latitude\": self.lat,\n",
        "            \"longitude\": self.lon,\n",
        "            \"start_date\": start_date.isoformat(),\n",
        "            \"end_date\": end_date.isoformat(),\n",
        "            \"hourly\": 'temperature_2m',\n",
        "            \"timezone\": \"auto\"\n",
        "        }\n",
        "        response = requests.get(base_url, params=payload)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if \"hourly\" in data:\n",
        "                df = pd.DataFrame(data[\"hourly\"])  # expects columns ['time', 'temperature_2m']\n",
        "                df['time'] = pd.to_datetime(df['time'])\n",
        "                df = df.set_index('time')\n",
        "                print(\"DONE!\")\n",
        "                return df\n",
        "            else:\n",
        "                print(\"No data found in the response.\")\n",
        "                return pd.DataFrame()\n",
        "        else:\n",
        "            print(f\"Request error: {response.status_code} - {response.text}\")\n",
        "            return pd.DataFrame()\n"
      ],
      "id": "p1A_WnGZMYpE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8mZxAMyMYpG"
      },
      "source": [
        "### Descarga de datos (Murcia)\n",
        "\n",
        "Vamos a usar el mecanismo que hemos creado para descargar la temperatura en Murcia durante los últimos 365 días.\n",
        "\n",
        "*Cambia los valores de las variables `latitude` y `longitude` por la ubicación que te interese.*"
      ],
      "id": "-8mZxAMyMYpG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qni1Ds9lMYpH"
      },
      "outputs": [],
      "source": [
        "latitude = 37.99235   # Madrid\n",
        "longitude = -1.13044\n",
        "end_date = datetime.date.today()\n",
        "start_date = end_date - datetime.timedelta(days=365)\n",
        "fetcher = TemperatureFetcher(latitude, longitude)\n",
        "df = fetcher._fetch_historical_temperature(start_date, end_date)\n",
        "print(df.shape)\n",
        "\n"
      ],
      "id": "qni1Ds9lMYpH"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HdVQT0E0Su_W"
      },
      "id": "HdVQT0E0Su_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "59TZZFvWJusU"
      },
      "id": "59TZZFvWJusU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqcEeVLTMYpI"
      },
      "source": [
        "## 3) Preprocesado básico\n",
        "\n",
        "- Nos quedamos con la columna `temperature_2m`.\n",
        "- Aseguramos que es una serie horaria completa (reindexando con frecuencias horarias) y rellenamos huecos (interpolación).\n",
        "- Escalamos los valores con `MinMaxScaler` para mejorar convergencia de las RNN."
      ],
      "id": "VqcEeVLTMYpI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i70JImaxMYpK"
      },
      "outputs": [],
      "source": [
        "if 'temperature_2m' not in df.columns:\n",
        "    raise ValueError('La columna temperature_2m no está presente en el DataFrame descargado.')\n",
        "\n",
        "series = df[['temperature_2m']].rename(columns={'temperature_2m': 'temp'})\n",
        "series = series.asfreq('H')\n",
        "series['temp'] = series['temp'].interpolate(method='time')\n",
        "scaler = MinMaxScaler()\n",
        "series['temp_scaled'] = scaler.fit_transform(series[['temp']])\n",
        "series.head()\n"
      ],
      "id": "i70JImaxMYpK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzEClQvzMYpO"
      },
      "outputs": [],
      "source": [
        "series['temp'].plot(figsize=(10,3));\n",
        "plt.tight_layout()\n"
      ],
      "id": "VzEClQvzMYpO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En ocasiones, la API que hemos usado para descargar los datos, devuelve al final una serie de valores repetidos que debemos de borrar."
      ],
      "metadata": {
        "id": "I66wvmIWIlYk"
      },
      "id": "I66wvmIWIlYk"
    },
    {
      "cell_type": "code",
      "source": [
        "series.tail()"
      ],
      "metadata": {
        "id": "ik2iq6azGr2U"
      },
      "id": "ik2iq6azGr2U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identificar el valor de la última fila\n",
        "ultima_temp= series.iloc[-1][\"temp\"]\n",
        "\n",
        "# eliminar todas las filas consecutivas desde el final que tienen ese valor\n",
        "while len(series) > 0 and series.iloc[-1][\"temp\"] == ultima_temp:\n",
        "    series = series.iloc[:-1]\n"
      ],
      "metadata": {
        "id": "E_aDqXlPGyLE"
      },
      "id": "E_aDqXlPGyLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series['temp'].plot(figsize=(10,3));\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "wtdsqW1rHbD9"
      },
      "id": "wtdsqW1rHbD9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series.tail()"
      ],
      "metadata": {
        "id": "33nPuFGTHd6c"
      },
      "id": "33nPuFGTHd6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJIHbv0FMYpQ"
      },
      "source": [
        "#### Crear secuencias para entrenamiento (sliding window)\n",
        "\n",
        "La función `create_sequences` crea pares `(X, y)` donde `X` es una ventana de `window_size` pasos y `y` es el valor a predecir `horizon` pasos adelante. Para la predicción un paso-ahead, `horizon=1`.\n",
        "\n",
        "También incluimos una función para crear conjuntos preparados para aprendizaje directo multi-step (salida con `horizon` pasos), si se desea entrenar un modelo que prediga varios pasos de una sola vez."
      ],
      "id": "VJIHbv0FMYpQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ubxDpugMYpQ"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "def create_sequences(values: np.ndarray, window_size: int, horizon: int = 1) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    X, y = [], []\n",
        "    for i in range(len(values) - window_size - (horizon - 1)):\n",
        "        X.append(values[i:i + window_size])\n",
        "        y.append(values[i + window_size: i + window_size + horizon])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "    if horizon == 1:\n",
        "        y = y.reshape((-1,))\n",
        "    return X, y"
      ],
      "id": "-ubxDpugMYpQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "KZ_K1omBJw1U"
      },
      "id": "KZ_K1omBJw1U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WGr9D6MYpS"
      },
      "source": [
        "## 4) Particionado train/val/test\n",
        "\n",
        "\n",
        "Separamos datos temporales respetando orden cronológico (no barajamos). Ajusta `train_frac` y `val_frac` según conveniencia."
      ],
      "id": "r9WGr9D6MYpS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Y5PkClMYpT"
      },
      "outputs": [],
      "source": [
        "values = series['temp_scaled'].values\n",
        "train_frac = 0.7\n",
        "val_frac = 0.15\n",
        "n = len(values)\n",
        "train_end = int(n * train_frac)\n",
        "val_end = int(n * (train_frac + val_frac))\n",
        "train_vals = values[:train_end]\n",
        "val_vals = values[train_end:val_end]\n",
        "test_vals = values[val_end:]\n",
        "print(f\"Train: {len(train_vals)}, Val: {len(val_vals)}, Test: {len(test_vals)}\")"
      ],
      "id": "X6Y5PkClMYpT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0Df6b9vpJx7M"
      },
      "id": "0Df6b9vpJx7M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1_Wvcc6MYpT"
      },
      "source": [
        "## 5) Nuestra primera Red Neuronal Recurrente con Keras\n",
        "\n"
      ],
      "id": "I1_Wvcc6MYpT"
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(url=\"https://raw.githubusercontent.com/fterroso/curso_ia_smart_cities/main/img/ml_simple_rnn.png\",width=800, height=300))"
      ],
      "metadata": {
        "id": "ZjSwhsFBWG7_"
      },
      "id": "ZjSwhsFBWG7_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Creamos una función para construir nuestra  `SimpleRNN`"
      ],
      "metadata": {
        "id": "GGGOf0_AWBW2"
      },
      "id": "GGGOf0_AWBW2"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_simple_rnn(window_size: int, units: int = 32) -> tf.keras.Model:\n",
        "    model = Sequential([\n",
        "        SimpleRNN(units, input_shape=(window_size, 1)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "H8gVS5x2VHLZ"
      },
      "id": "H8gVS5x2VHLZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "window_size = 24  # usar las últimas 24 horas para predecir la siguiente hora\n",
        "horizon = 1\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Crear secuencias\n",
        "X_train, y_train = create_sequences(train_vals, window_size, horizon)\n",
        "X_val, y_val = create_sequences(np.concatenate([train_vals[-window_size:], val_vals]), window_size, horizon)\n",
        "X_test, y_test = create_sequences(np.concatenate([val_vals[-window_size:], test_vals]), window_size, horizon)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "W7mCw9vEVLqh"
      },
      "id": "W7mCw9vEVLqh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos nuestro modelo\n",
        "rnn_model = build_simple_rnn(window_size, units=32)"
      ],
      "metadata": {
        "id": "4_P6V1W7D_CU"
      },
      "id": "4_P6V1W7D_CU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "history_rnn = rnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[es])"
      ],
      "metadata": {
        "id": "vrujvG_QVUAg"
      },
      "id": "vrujvG_QVUAg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history_rnn.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history_rnn.history['val_loss'], label='Validación')\n",
        "plt.legend()\n",
        "plt.title('Error de entrenamiento y validación (MSE)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxlDcaZYVdh6"
      },
      "id": "bxlDcaZYVdh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación 1-step\n",
        "\n",
        "Vamos ahora a evaluar nuestro primer predictor usando los datos reales como inputs para cada paso (modo teacher-forcing durante la evaluación)."
      ],
      "metadata": {
        "id": "FHvqhsOq5TDc"
      },
      "id": "FHvqhsOq5TDc"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_step_with_truth(model, X_true):\n",
        "    preds = model.predict(X_true).reshape(-1)\n",
        "    return preds"
      ],
      "metadata": {
        "id": "ku0PnuQ15dft"
      },
      "id": "ku0PnuQ15dft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_rnn_truth = predict_one_step_with_truth(rnn_model, X_test)"
      ],
      "metadata": {
        "id": "l5vAC9N05rU2"
      },
      "id": "l5vAC9N05rU2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar modelos de predicción de series temporales vamos a usar dos métricas muy comunes:\n",
        "\n",
        "\n",
        "- *MSE (Mean Squared Error)*: error cuadrático medio. Calcula el promedio de los errores al cuadrado, es decir:\n",
        "$$MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "\n",
        "Penaliza más fuertemente los errores grandes al elevarlos al cuadrado.\n",
        "\n",
        "- MAE (Error Absoluto Medio) mide la media de las diferencias absolutas entre los valores reales y las predicciones\n",
        "\n",
        "$$MAE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)$$\n"
      ],
      "metadata": {
        "id": "S5klh8Re92Dd"
      },
      "id": "S5klh8Re92Dd"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred, scaler):\n",
        "    y_true_inv = scaler.inverse_transform(y_true.reshape(-1, 1)).reshape(-1)\n",
        "    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1)\n",
        "    mse = mean_squared_error(y_true_inv, y_pred_inv)\n",
        "    mae = mean_absolute_error(y_true_inv, y_pred_inv)\n",
        "    return mse, mae"
      ],
      "metadata": {
        "id": "H_MNrotF5pMu"
      },
      "id": "H_MNrotF5pMu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_rnn, mae_rnn = compute_metrics(y_test, preds_rnn_truth, scaler)\n",
        "\n",
        "print('Predicción un timestamp a la vez:')\n",
        "print('RNN  MSE: {:.3f}, MAE: {:.3f}'.format(mse_rnn, mae_rnn))"
      ],
      "metadata": {
        "id": "6xww7xQS5wLV"
      },
      "id": "6xww7xQS5wLV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar_prediccion_vs_real(y_true, y_pred, scaler):\n",
        "    y_true_inv = scaler.inverse_transform(y_true.reshape(-1, 1)).reshape(-1)\n",
        "    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot( y_true_inv, label='Ground Truth', color='blue')\n",
        "    plt.plot( y_pred_inv, label='Predicción', color='red', linestyle='--')\n",
        "    plt.title('Comparación Serie Temporal: Real vs Predicha')\n",
        "    plt.xlabel('Tiempo')\n",
        "    plt.ylabel('Temperatura')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jKGOpt4Y-I8l"
      },
      "id": "jKGOpt4Y-I8l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_prediccion_vs_real(y_test, preds_rnn_truth, scaler)\n"
      ],
      "metadata": {
        "id": "Cc82qPD0-e8T"
      },
      "id": "Cc82qPD0-e8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Feature engineering*\n",
        "\n",
        "Una vez hemos realizado una primer aproximación, podemos añadir características temporales y estadísticas derivadas que suelen mejorar el rendimiento de modelos de series temporales:\n",
        "\n",
        "- Hora del día en forma cíclica (`sin`, `cos`) para capturar la periodicidad diaria.\n",
        "- Día de la semana en forma cíclica para capturar patrones semanales.\n",
        "- Lags: valores pasados de la temperatura (por ejemplo, 1h, 24h).\n",
        "- Estadísticas móviles: media y desviación típica de la ventana de 24h.\n",
        "\n",
        "Además mostraremos cómo crear secuencias multivariantes para entrenar RNN/LSTM/GRU con varias features."
      ],
      "metadata": {
        "id": "6ReIE_4ns914"
      },
      "id": "6ReIE_4ns914"
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir columnas de tiempo\n",
        "series_fe = series.copy()\n",
        "series_fe['hour'] = series_fe.index.hour\n",
        "series_fe['dayofweek'] = series_fe.index.dayofweek\n",
        "\n",
        "# Cíclicas para hora y día de la semana\n",
        "series_fe['hour_sin'] = np.sin(2 * np.pi * series_fe['hour'] / 24)\n",
        "series_fe['hour_cos'] = np.cos(2 * np.pi * series_fe['hour'] / 24)\n",
        "series_fe['dow_sin'] = np.sin(2 * np.pi * series_fe['dayofweek'] / 7)\n",
        "series_fe['dow_cos'] = np.cos(2 * np.pi * series_fe['dayofweek'] / 7)\n",
        "\n",
        "# Lags (1h, 24h) sobre la temperatura original (no escalada) y luego escalamos\n",
        "series_fe['lag_1'] = series_fe['temp'].shift(1)\n",
        "series_fe['lag_24'] = series_fe['temp'].shift(24)\n",
        "\n",
        "# Rolling statistics\n",
        "series_fe['roll_mean_24'] = series_fe['temp'].rolling(window=24, min_periods=1).mean()\n",
        "series_fe['roll_std_24'] = series_fe['temp'].rolling(window=24, min_periods=1).std().fillna(0)\n",
        "\n",
        "# Rellenar NA que aparezcan por lag\n",
        "series_fe = series_fe.fillna(method='bfill')\n",
        "\n",
        "# Selección de features a usar\n",
        "feature_cols = ['temp', 'lag_1', 'lag_24', 'roll_mean_24', 'roll_std_24', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
        "\n",
        "# Escalar features\n",
        "scaler_fe = MinMaxScaler()\n",
        "series_fe_scaled = scaler_fe.fit_transform(series_fe[feature_cols])\n",
        "\n",
        "# Convertir a DataFrame para mantener etiquetas\n",
        "df_fe = pd.DataFrame(series_fe_scaled, index=series_fe.index, columns=feature_cols)\n",
        "df_fe.head()"
      ],
      "metadata": {
        "id": "omKhQctTtFdI"
      },
      "id": "omKhQctTtFdI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Actualizamos `create_sequences` para aceptar múltiples features y devolver X con shape `(n_samples, window_size, n_features)`."
      ],
      "metadata": {
        "id": "sTq2xUdlq_Bx"
      },
      "id": "sTq2xUdlq_Bx"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_multivariate(values: np.ndarray, window_size: int, horizon: int = 1):\n",
        "    X, y = [], []\n",
        "    n = values.shape[0]\n",
        "    for i in range(n - window_size - (horizon - 1)):\n",
        "        X.append(values[i:i + window_size])\n",
        "        y.append(values[i + window_size: i + window_size + horizon, 0])  # target is la primera columna (temp)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    if horizon == 1:\n",
        "        y = y.reshape((-1,))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "6NKfd7QEq51g"
      },
      "id": "6NKfd7QEq51g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear particiones temporales para las features\n",
        "values_fe = df_fe.values\n",
        "n = len(values_fe)\n",
        "train_end = int(n * 0.7)\n",
        "val_end = int(n * 0.85)\n",
        "train_vals_fe = values_fe[:train_end]\n",
        "val_vals_fe = values_fe[train_end:val_end]\n",
        "test_vals_fe = values_fe[val_end:]\n",
        "\n",
        "window_size = 24\n",
        "horizon = 1\n",
        "X_train_fe, y_train_fe = create_sequences_multivariate(train_vals_fe, window_size, horizon)\n",
        "X_val_fe, y_val_fe = create_sequences_multivariate(np.concatenate([train_vals_fe[-window_size:], val_vals_fe]), window_size, horizon)\n",
        "X_test_fe, y_test_fe = create_sequences_multivariate(np.concatenate([val_vals_fe[-window_size:], test_vals_fe]), window_size, horizon)\n",
        "\n",
        "print('Tamaño de la serie temporal multivariante:', X_train_fe.shape, y_train_fe.shape)"
      ],
      "metadata": {
        "id": "bdXXCCGcDJvy"
      },
      "id": "bdXXCCGcDJvy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volvemos a entrenar nuestro modelo con el dataset multivariante"
      ],
      "metadata": {
        "id": "B_lvKcGbC9Ma"
      },
      "id": "B_lvKcGbC9Ma"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_simple_rnn_fe(window_size: int, num_features: int, units: int = 32) -> tf.keras.Model:\n",
        "    model = Sequential([\n",
        "        SimpleRNN(units, input_shape=(window_size, num_features)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "h70kiuf8DvXT"
      },
      "id": "h70kiuf8DvXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_fe.shape"
      ],
      "metadata": {
        "id": "Ws4IfYhKEO3Y"
      },
      "id": "Ws4IfYhKEO3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model_fe= build_simple_rnn_fe(window_size, X_train_fe.shape[2], units=32)"
      ],
      "metadata": {
        "id": "B9H5oZNMD2-7"
      },
      "id": "B9H5oZNMD2-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_rnn_fe = rnn_model_fe.fit(X_train_fe, y_train_fe, validation_data=(X_val_fe, y_val_fe), epochs=epochs, batch_size=batch_size, callbacks=[es])"
      ],
      "metadata": {
        "id": "p8n09OS_CvUM"
      },
      "id": "p8n09OS_CvUM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history_rnn_fe.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history_rnn_fe.history['val_loss'], label='Validación')\n",
        "plt.legend()\n",
        "plt.title('Error de entrenamiento y validación (MSE)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u-9Wlo5oMp8b"
      },
      "id": "u-9Wlo5oMp8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_rnn_truth_fe = predict_one_step_with_truth(rnn_model_fe, X_test_fe)"
      ],
      "metadata": {
        "id": "YVxrtSpvEoH8"
      },
      "id": "YVxrtSpvEoH8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_rnn, mae_rnn = compute_metrics(y_test_fe, preds_rnn_truth_fe, scaler)\n",
        "\n",
        "print('Predicción un timestamp a la vez con feature engineering:')\n",
        "print('RNN(FE)  MSE: {:.3f}, MAE: {:.3f}'.format(mse_rnn, mae_rnn))"
      ],
      "metadata": {
        "id": "NUJ2QExMEvm8"
      },
      "id": "NUJ2QExMEvm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_prediccion_vs_real(y_test_fe, preds_rnn_truth_fe, scaler)"
      ],
      "metadata": {
        "id": "k5q6u311GAf0"
      },
      "id": "k5q6u311GAf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes LSTM"
      ],
      "metadata": {
        "id": "XjuKwX7iIyCN"
      },
      "id": "XjuKwX7iIyCN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las redes neuronales recurrentes (RNN) están diseñadas para trabajar con datos secuenciales, como series temporales o texto, ya que permiten que la información fluya de un paso temporal a otro. Sin embargo, las RNN más simples (denominadas SimpleRNN) presentan una limitación importante: tienen dificultades para aprender dependencias a largo plazo debido al problema del desvanecimiento y explosión del gradiente durante el entrenamiento. Esto provoca que la red solo recuerde información de pocos pasos anteriores, perdiendo el contexto más lejano de la secuencia.\n",
        "\n",
        "Para resolver este problema se introdujeron las LSTM (Long Short-Term Memory), un tipo avanzado de RNN. Las LSTM incorporan una arquitectura interna más compleja con puertas (de entrada, olvido y salida) y una celda de memoria que permiten:\n",
        "\n",
        "- Recordar información relevante durante largos intervalos de tiempo.\n",
        "\n",
        "- Olvidar información innecesaria de manera controlada.\n",
        "\n",
        "- Evitar el problema del desvanecimiento del gradiente, lo que mejora la estabilidad del entrenamiento.\n",
        "\n",
        "En resumen, las LSTM mejoran a las SimpleRNN porque pueden capturar dependencias a largo plazo en las series temporales, lo que las hace más adecuadas para problemas donde el pasado lejano influye en el futuro (como predicciones de clima, lenguaje natural o secuencias financieras)."
      ],
      "metadata": {
        "id": "3DwBImMZI_3M"
      },
      "id": "3DwBImMZI_3M"
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(url=\"https://raw.githubusercontent.com/fterroso/curso_ia_smart_cities/main/img/ml_lstm.png\",width=900, height=300))"
      ],
      "metadata": {
        "id": "L0vVuwotKeHk"
      },
      "id": "L0vVuwotKeHk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm(window_size: int, units: int = 32) -> tf.keras.Model:\n",
        "    model = Sequential([\n",
        "        LSTM(units, input_shape=(window_size, 1)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JeYVxqMpJA4M"
      },
      "id": "JeYVxqMpJA4M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "window_size = 24  # usar las últimas 24 horas para predecir la siguiente\n",
        "horizon = 1\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Crear secuencias (univariado)\n",
        "X_train, y_train = create_sequences(train_vals, window_size, horizon)\n",
        "X_val, y_val = create_sequences(np.concatenate([train_vals[-window_size:], val_vals]), window_size, horizon)\n",
        "X_test, y_test = create_sequences(np.concatenate([val_vals[-window_size:], test_vals]), window_size, horizon)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "Jn7a_9oWJLG0"
      },
      "id": "Jn7a_9oWJLG0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos la red LSTM\n",
        "lstm_model = build_lstm(window_size, units=32)"
      ],
      "metadata": {
        "id": "FP8v09MiJOWL"
      },
      "id": "FP8v09MiJOWL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo\n",
        "history_lstm = lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[es])"
      ],
      "metadata": {
        "id": "3xl6ilnbJONs"
      },
      "id": "3xl6ilnbJONs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history_lstm.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history_lstm.history['val_loss'], label='Validación')\n",
        "plt.legend()\n",
        "plt.title('Error de entrenamiento y validación (MSE)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rdEd8vQXMefc"
      },
      "id": "rdEd8vQXMefc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_lstm_truth = predict_one_step_with_truth(lstm_model, X_test)"
      ],
      "metadata": {
        "id": "hra2Q8G7M9QD"
      },
      "id": "hra2Q8G7M9QD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_rnn, mae_rnn = compute_metrics(y_test, preds_lstm_truth, scaler)\n",
        "\n",
        "print('Predicción un timestamp a la vez:')\n",
        "print('LSTM  MSE: {:.3f}, MAE: {:.3f}'.format(mse_rnn, mae_rnn))"
      ],
      "metadata": {
        "id": "l4cz06g0NDoM"
      },
      "id": "l4cz06g0NDoM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_prediccion_vs_real(y_test, preds_lstm_truth, scaler)\n"
      ],
      "metadata": {
        "id": "RwfLAqpUNNH7"
      },
      "id": "RwfLAqpUNNH7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes GRU"
      ],
      "metadata": {
        "id": "b4MjtFMXL1-K"
      },
      "id": "b4MjtFMXL1-K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avewJfaiMYpU"
      },
      "outputs": [],
      "source": [
        "def build_gru(window_size: int, units: int = 32) -> tf.keras.Model:\n",
        "    model = Sequential([\n",
        "        GRU(units, input_shape=(window_size, 1)),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "id": "avewJfaiMYpU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear secuencias (univariado)\n",
        "X_train, y_train = create_sequences(train_vals, window_size, horizon)\n",
        "X_val, y_val = create_sequences(np.concatenate([train_vals[-window_size:], val_vals]), window_size, horizon)\n",
        "X_test, y_test = create_sequences(np.concatenate([val_vals[-window_size:], test_vals]), window_size, horizon)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "491IqNyKOZoz"
      },
      "id": "491IqNyKOZoz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = build_gru(window_size, units=32)\n",
        "history_gru = gru_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[es])"
      ],
      "metadata": {
        "id": "yA5A3mQCOdUz"
      },
      "id": "yA5A3mQCOdUz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(history_gru.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history_gru.history['val_loss'], label='Validación')\n",
        "plt.legend()\n",
        "plt.title('Error de entrenamiento y validación (MSE)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1bHemtbBOi6r"
      },
      "id": "1bHemtbBOi6r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_gru_truth = predict_one_step_with_truth(gru_model, X_test)\n",
        "\n",
        "mse_gru, mae_gru = compute_metrics(y_test, preds_gru_truth, scaler)\n",
        "\n",
        "print('Predicción un timestamp a la vez:')\n",
        "print('GRU  MSE: {:.3f}, MAE: {:.3f}'.format(mse_gru, mae_gru))"
      ],
      "metadata": {
        "id": "cQglPtgfOsDE"
      },
      "id": "cQglPtgfOsDE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_prediccion_vs_real(y_test, preds_gru_truth, scaler)"
      ],
      "metadata": {
        "id": "Kg9zJBOuO677"
      },
      "id": "Kg9zJBOuO677",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlSQBtNHMYpX"
      },
      "source": [
        "### Prediccion autoregresiva\n",
        "\n",
        "Vamos a evaluar otra forma de usar el predictor usando un modo autoregresivo en donde retroalimentamos las predicciones para generar el siguiente timestamp."
      ],
      "id": "WlSQBtNHMYpX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3i6rAQVMYpY"
      },
      "outputs": [],
      "source": [
        "def predict_recursive(model, seed_sequence: np.ndarray, n_steps: int) -> np.ndarray:\n",
        "    window = seed_sequence.copy().reshape((window_size,))\n",
        "    preds = []\n",
        "    for _ in range(n_steps):\n",
        "        x_in = window.reshape((1, window_size, 1))\n",
        "        p = model.predict(x_in).reshape(-1)[0]\n",
        "        preds.append(p)\n",
        "        window = np.roll(window, -1)\n",
        "        window[-1] = p\n",
        "    return np.array(preds)\n"
      ],
      "id": "J3i6rAQVMYpY"
    },
    {
      "cell_type": "code",
      "source": [
        "horizon_steps = 24\n",
        "seed_seq = X_test[-1].reshape((-1,))\n",
        "preds_rnn_recursive = predict_recursive(rnn_model, seed_seq, horizon_steps)\n",
        "preds_lstm_recursive = predict_recursive(lstm_model, seed_seq, horizon_steps)\n",
        "preds_gru_recursive = predict_recursive(gru_model, seed_seq, horizon_steps)"
      ],
      "metadata": {
        "id": "YHc8WhWQPuoL"
      },
      "id": "YHc8WhWQPuoL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG7StCkiMYpZ"
      },
      "outputs": [],
      "source": [
        "preds_rnn_recursive_inv = scaler.inverse_transform(preds_rnn_recursive.reshape(-1, 1)).reshape(-1)\n",
        "preds_lstm_recursive_inv = scaler.inverse_transform(preds_lstm_recursive.reshape(-1, 1)).reshape(-1)\n",
        "preds_gru_recursive_inv = scaler.inverse_transform(preds_gru_recursive.reshape(-1, 1)).reshape(-1)"
      ],
      "id": "nG7StCkiMYpZ"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(preds_rnn_recursive_inv, label='RNN recursivo')\n",
        "plt.plot(preds_lstm_recursive_inv, label='LSTM recursivo')\n",
        "plt.plot(preds_gru_recursive_inv, label='GRU recursivo')\n",
        "plt.legend()\n",
        "plt.title('Predicciones autoregresivas (24 horas a partir de la última ventana de test)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BxdLO5dkPx-s"
      },
      "id": "BxdLO5dkPx-s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px1lsCn5MYpb"
      },
      "source": [
        "## Conclusiones: diferencias entre RNN, LSTM y GRU\n",
        "\n",
        "- **RNN simple (SimpleRNN):** unidad recurrente básica. Mantiene un estado oculto que se actualiza cada paso. Sufre del problema de *vanishing gradients* para dependencias a largo plazo; suele ser rápido y simple, apropiado para relaciones a corto plazo.\n",
        "- **LSTM (Long Short-Term Memory):** introduce una celda de memoria y puertas (input, forget, output) que controlan el flujo de información. Diseñado para aprender dependencias a largo plazo y evitar el *vanishing gradient*.\n",
        "- **GRU (Gated Recurrent Unit):** versión simplificada de LSTM con menos puertas (update/reset). A menudo alcanza rendimientos similares a LSTM con menos parámetros y entrenamiento más rápido.\n"
      ],
      "id": "px1lsCn5MYpb"
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(url=\"https://raw.githubusercontent.com/fterroso/curso_ia_smart_cities/main/img/ml_rnn_lstm_gru.png\",width=900, height=400))"
      ],
      "metadata": {
        "id": "9t9y2WpZJ3sc"
      },
      "id": "9t9y2WpZJ3sc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jk4PuQzkJzxT"
      },
      "id": "jk4PuQzkJzxT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSVhpid0MYpb"
      },
      "source": [
        "## Ejercicios propuestos\n",
        "\n",
        "1. Experimenta con el `window_size`.\n",
        "2. Horizon: prueba `horizon=1` vs `horizon=24`\n",
        "3. Features adicionales: añade variables como hora del día, día de la semana, variables meteorológicas auxiliares.\n",
        "4. Escalado: probar `StandardScaler` frente a `MinMaxScaler`.\n",
        "\n",
        "\n",
        "¡Eso es todo amigos!"
      ],
      "id": "PSVhpid0MYpb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}